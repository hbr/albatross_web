\section{Inductive Data Types}

Using inductive data types is a very powerful way to define the structure of
data. Functional languages or languages with a strong functional component
like Ocaml, Haskell, FSharp, Swift, Coq, etc. use inductive data types as its
central concept to define data. Inductive data types are also known as
algebraic data types.


\subsection{Basics of Inductive Types}

A very simple inductive type is an enumeration type. To define a type which
represents a day of the week we can use the declaration

\begin{lstlisting}
    case class
        DAY
    create
        monday
        tuesday
        wednesday
        thursday
        friday
        saturday
        sunday
    end
\end{lstlisting}

The keyword \lstinline!case! tells the compiler that an inductive type is
being declared. Each inductive type has a list of constructors which consists
at least of one element. The above type has one constructor for each day of
the week.

Pattern matching can be used to define a function which maps each weekday to
its next weekday.

\begin{lstlisting}
    next (d:DAY): DAY
        -> inspect d
           case monday    then tuesday
           case tuesday   then wednesday
           case wednesday then thursday
           case thursday  then friday
           case friday    then saturday
           case saturday  then sunday
           case sunday    then monday
           end
\end{lstlisting}

The Albatross compiler can use pattern matching within proofs to do term
rewriting. E.g. it can rewrite the term \lstinline!next(monday)! to
\lstinline!tuesday!. We can use this feature to prove the following
assertions:

\begin{lstlisting}
    all ensure
        next(sunday) = monday

        sunday.next.next.next = wednesday
    end
\end{lstlisting}

Note that in Albatross the terms \lstinline!f(x)! and  \lstinline!x.f! are
equivalent. The object oriented notation is more convenient for iterated
function applications because nested parentheses can be avoided.

The compiler generates for each inductive type an equality function. Therefore
the expressions in the previous proof are well typed. Furthermore each
inductive type automatically inherits ANY.

The compiler guarantees that two objects created with different constructors
are different. I.e. the following assertions are generated by the compiler.

\begin{lstlisting}
    all ensure
            -- generated by the compiler
        monday  = tuesday    ==>  false
        tuesday = wednesday  ==>  false
        ... -- all other possible combinations
    end
\end{lstlisting}
These inversion laws can help us to do proofs by contradiction.

Inductive types can contain data. An inductive type can be declared which has
an optional element and an inductive type can be declared which has a list of
elements.

\begin{lstlisting}
    G: ANY

    case class
        OPTION[G]
    create
        none
        value (item:G)
    end

    case class
        LIST[G]
    create
        [] 
        (^) (head:G, tail:LIST[G])
    end
\end{lstlisting}

The compiler generates automatically deconstructors for inductive types with
data. For the above types the following functions are generated.

\begin{lstlisting}
    item (o:OPTION[G]): G          -- generated by the compiler
        require
            o as value(_)
        ensure
            Result = inspect o
                     case value(v) then v
                     end
        end

    head (l:LIST[G]): G            -- generated by the compiler
        require
            l as _^_               -- '_' is an unnamed variable
        ensure
            Result = inspect l
                     case h ^ _  then h
                     end
        end

    tail (l:LIST[G]): LIST[G]      -- generated by the compiler
        require
            l as _^_
        ensure
            Result = inspect l
                     case _ ^ t  then t
                     end
        end
\end{lstlisting}
 
The boolean expression \lstinline!o as value(_)! tests if the object
\lstinline!o! has been constructed with the constructor \lstinline!value!. The
underline character \lstinline!_! is used for variables whose name is not
interesting.

Clearly all these functions need preconditions because the used pattern
matching in the definition of the functions is not complete. You cannot
extract an element if the optional has been constructed with \lstinline!none!
and you cannot get neither the head nor the tail of an empty list.





\subsection{Recursion and Induction}


Natural numbers can be declared with an inductive type.

\begin{lstlisting}
    case class
        NATURAL
    create
        0
        successor(predecessor:NATURAL)
    end
\end{lstlisting}

This definition says that a natural number is either \lstinline!0! or the
successor of some other natural number which is called its predecessor. There
are no other possibilities to construct natural numbers.

The addition of two natural numbers can be defined recursively.

\begin{lstlisting}
    (+) (a,b:NATURAL): NATURAL
        -> inspect b
           case 0 then a
           case successor(n) then (a + n).successor
           end
\end{lstlisting}


Albatross allows only recursive calls which are sound i.e. whose termination
is guaranteed. Therefore the recursion checker of the Albatross compiler
checks two things for a recursive call:

\begin{itemize}
\item At least one argument of the recursive call has to be structurally
  smaller than the original argument.
\item The recursive call has to be within a branch.
\end{itemize}

The above definition of the function \lstinline!+! satisfies both
criteria. The argument \lstinline!n! is the predecessor of the argument
\lstinline!b! of the original call and the call occurs within a case branch of
an inspect expression.

The first criterion is needed to guarantee that the execution of the function
at runtime terminates. The second one is needed to guarantee that unfolding
definitions at compile time is guaranteed to terminate because the compiler
unfolds definitions outside of branches arbitrarily and within branches only
if it can prove that the branch is entered.

In order to prove properties of recursive functions we need an induction
law. The compiler generates for all inductive types an induction
law. Examples:

\begin{lstlisting}
    all(p:DAY?)   -- generated by the compiler
        require
            p(monday);   p(tuesday); p(wednesday)
            p(thursday); p(friday)
            p(saturday); p(sunday)
        ensure
            all(d) d in p
        end  
\end{lstlisting}

In order to prove that all days of the week satisfy a certain property we have
to prove that \lstinline!monday! satisfies the property, \lstinline!tuesday!
satisfies the property, ..., and \lstinline!sunday! satisfies the property.

\begin{lstlisting}
    all(p:OPTION[G]?)   -- generated by the compiler
        require
            none in p
            all(v) value(v) in p
        ensure
            all(o) o in p
        end  
\end{lstlisting}

In order to prove that all objects with an optional element satisfy a certain
property we have to prove that \lstinline!none! satisfies the property and
that for all values \lstinline!v! the object \lstinline!value(v)! satisfies
the property.

We see that for each constructor we get a premise to satisfy in order to prove
that all objects satisfy the property.



Now let us look at lists which have one recursive constructor (\lstinline!^!)
which needs an already constructed list to construct a new list by prepending
a head element in front of the list. For lists we get the induction principle

\begin{lstlisting}
    all(p:LIST[G]?)   -- generated by the compiler
        require
            []  in p
            all(h,a) a in p ==> h^a in p
        ensure
            all(a) a in p
        end  
\end{lstlisting}
We see that each constructor gets a premise to satisfy. However the recursive
constructor gets a premise with an induction hypothesis.

Let us express the induction law in words in order to understand it.

In order to prove that all lists satisfy a certain property we have to prove
that the empty list satisfies the property and for all elements and lists it
has to be shown: If the list satisfies the property then the list with the new
element in front satisfies the property as well.

Since all lists have to be constructed with one of the constructors only list
which satisfy the property can be constructed.

The generated induction principle for natural numbers is very similar to the
one generated for lists.

\begin{lstlisting}
    all(p:NATURAL?)   -- generated by the compiler
        require
            0 in p
            all(n) n in p ==> n.successor in p
        ensure
            all(n) n in p
        end  
\end{lstlisting}
Since the constructor \lstinline!successor! is recursive (i.e. it needs a
natural number to construct a new one) the premise which corresponds to this
constructor gets an induction hypothesis as well.

There remains one little detail. The proof engine of Albatross bubbles up all
universal quantifiers which appear in the conclusion of a law i.e. for natural
numbers the compiler generates the induction principle in the form
\begin{lstlisting}
    all(p:NATURAL?, n:NATURAL)   -- generated by the compiler
        require
            0 in p
            all(n) n in p ==> n.successor in p
        ensure
            n in p
        end  
\end{lstlisting}
which is equivalent to the former presentation (Note that the variable
\lstinline!n! does not occur free in the premises). In this form the proof
engine can work with it more systemtically.


Now let's see how to prove some properties of addition by using the induction
law of natural numbers.

If the declared type \lstinline!NATURAL! correponds to our intuitive notion of
natural numbers we should be able to prove \lstinline!0 + a = a! for all
natural numbers \lstinline!a!. We generate the proof step by step in all
details.

In order to use the induction principle we need a property i.e. a predicate
over natural numbers. Since there is only one variable there is no choice.
\begin{lstlisting}
     a in {a: 0 + a = a}
\end{lstlisting}
This expression if obviously equivalent to our goal. But in this form it
matches the conclusion of the induction law. The template of the proof by
induction looks like
\begin{lstlisting}
    all(a:NATURAL)
        proof
            ...
            0 in {a:NATURAL: 0 + a = a}  -- explicit type to avoid
                                         -- ambiguities
            all(n:NATURAL)
                require
                    n in {a: 0 + a = a}
                proof
                    0 + n = n
                    ...
                    0 + n.successor = n.successor
                ensure
                    n.successor in {a: 0 + a = a}
                end

            a in {a: 0 + a = a}
        ensure
            0 + a = a
        end
\end{lstlisting}

The induction start is verified by the proof engine by making the following
backward steps:
\begin{lstlisting}
    -- read bottoms up
    0 = 0                         -- reflexivity of '='

    0 + 0 = 0                     -- apply function '+'

    0 in {a:NATURAL: 0 + a = a}   -- substitute 'a' by '0'
\end{lstlisting}

The induction step is verified by backward reasoning as well.
\begin{lstlisting}
    -- read bottoms up
    n.successor = n.successor       -- reflexivity of '='

    (0 + n).successor = n.succesor  -- use induction hypothesis

    0 + n.successor = n.successor   -- apply function '+'

    n.successor in {a: 0 + a = a}   -- substitute 'a' by n.successor 
\end{lstlisting}

Note that nearly all steps presented for this proof are done automatically by
the proof engine. The proof engine needs just a hint to do a proof by
induction. Therefore the following minimal version of the proof is sufficient.

\begin{lstlisting}
    all(a:NATURAL)
        proof
            0 in {a:NATURAL: 0 + a = a}
            a in {a:NATURAL: 0 + a = a}
        ensure
            0 + a = a
        end
\end{lstlisting}

This is the standard form of a proof by induction where the proof engine
receives just a trigger to apply the induction law and can do the rest of the
work alone. The first assertion is proved trivially and after the proof
forward reasoning puts the following partial specialization of the induction
law into the context
\begin{lstlisting}
     all(n)
         (all(n) n in {a:NATURAL: 0 + a = a}
                 ==> n.successor in {a:NATURAL: 0 + a = a})
         ==>
         n in {a:NATURAL: 0 + a = a}
\end{lstlisting}

The second assertion matches the target of this partial specialization and can
therefore trigger backward reasoning which succeeds automatically as
demonstrated above.

Let's come to the next law of addition: associativity. In order to prove it
the proof engine needs just a hint to apply the induction law.

\begin{lstlisting}
    all(a,b,c:NATURAL)
        proof
            0 in {c: (a + b) + c = a + (b + c)}
            c in {c: (a + b) + c = a + (b + c)}
        ensure
            (a + b) + c = a + (b + c)
        end
\end{lstlisting}

It might be interesting for the reader to prove this assertion in the same
manner as the proof engine.


The proof of commutativity of addition (i.e. \lstinline!a + b = b + a!) is
little bit more complex. Again we trigger the induction law to get the
partially finished proof:

\begin{lstlisting}
    all(a,b:NATURAL)
        proof
            ...
            0 in {b: a + b = b + a}

            all(b)
                require
                    b in {b: a + b = b + a}
                proof
                    a + b = b + a
                    ...
                    (a + b).successor = b.successor + a
                    a + b.successor = b.succesor + a
                ensure
                    b.successor in {b: a + b = b + a}
                end

            b in {b: a + b = b + a}
        ensure
            a + b = b + a
        end
\end{lstlisting}

Now look at the induction start. The proof engine tries backward reasoning
\begin{lstlisting}
    -- read bottoms up
    a = 0 + a                   -- proof engine cannot continue!!

    a + 0 = 0 + a               -- apply '+' to the left hand side

    0 in {b: a + b = b + a}     -- substitute 'b'
\end{lstlisting}

Why is the proof engine stuck here? We have already proved the law
\lstinline!0 + a = a! and from the module \lstinline!predicate_logic! we know
that \lstinline!=! is symmetric. The problem: The above presented backward
steps are not completely correct. When the proof engine sees \lstinline!a + 0!
\lstinline!= 0 + a! it unfolds definitions until no more unfolding is
possible. Therefore we do not get \lstinline!a = 0 + a! as a goal because the
addition can still be unfolded. Instead we get

\begin{lstlisting}
    a = inspect a
        case 0 then 0
        case successor(n) then (0 + n).successor
        end
\end{lstlisting}
Unfortunately this goal cannot be resolved. We have to tell the proof engine
to use \lstinline!0 + a = a! as a simplification. We do this by writing

\begin{lstlisting}
    proof  0 + a = a
    ensure 0 in {b: a + b = b + a} end
\end{lstlisting}

Now the proof engine can do the following backward reasoning steps:

\begin{lstlisting}
    -- read bottoms up
    a = a                       -- proved by reflexivity of '='

    a + 0 = a                   -- apply '+' to the left hand side

    a + 0 = 0 + a               -- apply simplification

    0 in {b: a + b = b + a}     -- substitute 'b'
\end{lstlisting}

Now we have to look at the unfinished induction step.

\begin{lstlisting}
      a + b = b + a
      ...
      (a + b).successor = b.successor + a
\end{lstlisting}

The first term can be transformed via the induction hypothesis into
\begin{lstlisting}
      (a + b).successor = (b + a).successor   -- induction hypothesis
      (b + a).successor = b + a.successor     -- apply '+' to right hand side
\end{lstlisting}

Now the remaining missing link is

\begin{lstlisting}
      ...
      b + a.successor = b.successor + a
\end{lstlisting}

Unfortunately this statement cannot be proved directly it needs an own proof
by induction. If we try induction on \lstinline!a! we get the induction step
\begin{lstlisting}
      b + a.successor = b.successor + a
      ...
      (b + a.successor).successor = (b.successor + a).successor
      b + a.successor.successor   = b.successor + a.successor
\end{lstlisting}
which succeeds trivially by applying the induction hypothesis. It is good
practive to separate out this proof.

\begin{lstlisting}
    all(a,b:NATURAL)
            -- lemma
        proof
            0 in {a: b + a.successor = b.successor + a}
            a in {a: b + a.successor = b.successor + a}
        ensure
            b + a.successor = b.successor + a
        end
\end{lstlisting}

Having this lemma the proof of commutativity of addition can be completed.

\begin{lstlisting}
    all(a,b:NATURAL)
        proof
            proof  0 + a = a
            ensure 0 in {b: a + b = b + a} end

            all(b)
                require
                    a + b = b + a
                proof
                    a + b.successor   = (a + b).successor  -- apply '+'
                    (a + b).successor = (b + a).successor  -- induction
                                                           --  hypothesis
                    (b + a).successor = b + a.successor    -- apply '+'
                    b + a.successor   = b.successor + a    -- lemma
                ensure
                    a + b.successor = b.successor + a
                end

            b in {b: a + b = b + a}
        ensure
            a + b = b + a
        end
\end{lstlisting}

In this proof just the essential steps have been kept and nearly all steps
which can be done by the proof engine automatically have been left out. This
has the advantage that we not only have a proof which can be formally checked
but also a proof which presents all important steps to the reader.

\subsection{Inversion and Injection Laws}

Work in progress.

\subsection{Binary Tree}

A binary tree is either empty (i.e. a leaf) or it contains an
information element and a left and a right subtree. A corresponding
declaration in Albatross formalizes this informal description.


\begin{lstlisting}
    case class
        BINARY_TREE[G]
    create
        leaf
        tree (info:G, left,right:BINARY_TREE[G])
    end
\end{lstlisting}

The generated induction principle is

\begin{lstlisting}
    all(p:BINARY_TREE[G]?, t:BINARY_TREE[G])
        require
            leaf in p

            all(i,l,r) l in p ==> r in p ==> tree(i,l,r) in p
        ensure
            t in p
        end
\end{lstlisting}

We write a function to mirror a binary tree as a recursive function

\begin{lstlisting}
    (-) (t:BINARY_TREE[G]): BINARY_TREE[G]
        -> inspect t
           case leaf        then leaf
           case tree(i,l,r) then tree(i,-r,-l)
           end
\end{lstlisting}

The mirroring of a tree should be an involution i.e. mirroring a tree twice
should return the original tree. This assertion can be proved by induction.

\begin{lstlisting}
    all(t: BINARY_TREE[G])
        proof
            leaf in {t: t = - (- t)}

            all(i,l,r)
                require
                    l = - (- l)
                    r = - (- r)
                ensure
                    tree(i,l,r) = - (- tree(i,l,r))
                end

            t in {t: t = - (- t)}
        ensure
            t = - (- t)
        end
\end{lstlisting}

We have used three intermediate assertions to prove the goal. For the proof
engine the second is unnecessary. It has been added here for documentation
purposes.


As a next step we define a recursive function which calculates the inorder
sequence of a tree.

\begin{lstlisting}
    -- note: for the following we assume that the module 'list' of the
    --       base library is used in the current module!

    inorder (t:BINARY_TREE[G]): [G]
        -> inspect t
           case leaf then [] 
           case tree(i,l,r) then l.inorder + i ^ r.inorder
           end
\end{lstlisting}

In words: The inorder sequence of an empty tree is the empty list. The inorder
sequence of a nonempty tree is the inorder sequence of the left subtree
concatenated with info-prefixed inorder sequence of the right subtree.

Note that we use the module \lstinline!list! of the base library. It has the
same declaration as the list of the previous chapters. However since lists are
used very frequently the type \lstinline!LIST[G]! of the basic libary can be
abbreviated with \lstinline![G]!.

Furthermore the parser of the Albatross language converts every expression of
the form \lstinline![a,b,...z]! to \lstinline!a^b^...^z^[] !. This mechanism
is a pure macro facility i.e. it works for any type which declares a constant
\lstinline![] ! and a binary operator \lstinline!^! (provided that the
expanded expression passes the type checker).

The module \lstinline!list! of the base library provides a lot of functions
and proves a lot of useful assertions. In the following we use the following
functions and assertions.

\begin{lstlisting}
     -- from the module 'alba.base.list'

     (+) (a,b:[G]): [G]
             -- The concatenation of the lists 'a' and 'b'
         -> inspect a
            case []  then b
            case h^t then h^(t + b)
            end

     (-) (a:[G]): [G]
             -- The mirrored list 'a'
         -> inspect a
            case []  then [] 
            case h^t then - t + [h]
            end

     all(a,b,c:[G])
         ensure
             (a + b) + c = a + (b + c)   -- associative
             
             (- (a + b)) = -b + -a       -- mirror concatenation

             a = - (- a)                 -- involution
         end
\end{lstlisting}

What is the inorder sequence of a mirrored tree? Obviously the mirrored
inorder sequence of the original tree. The following assertion proves this
claim.

\begin{lstlisting}
    all(t:BINARY_TREE[G])
    proof
        leaf in {t: (-t).inorder = - t.inorder}

        all(i:G, l,r:BINARY_TREE[G])
            require
                (-l).inorder = - l.inorder
                (-r).inorder = - r.inorder
            proof
                (-tree(i,l,r)).inorder            -- unfold definitions
                    = -r.inorder + ([i] + -l.inorder)

                (-r).inorder + ([i] + -l.inorder) -- associativity
                    = ((-r).inorder + [i]) + -l.inorder

                ((-r).inorder + [i]) + -l.inorder -- unfold definition
                    = -i^r.inorder + -l.inorder

                (-i^r.inorder) + -l.inorder       -- mirror concatenation
                    = - (l.inorder + i ^ r.inorder)

                (- (l.inorder + i ^ r.inorder))   -- unfold definition
                    = - tree(i,l,r).inorder
            ensure
                (-tree(i,l,r)).inorder = - tree(i,l,r).inorder
            end

        t    in {t: (-t).inorder = - t.inorder}
    ensure
        (-t).inorder = - t.inorder
    end  
\end{lstlisting}

Note how a proof expressed in this form serves two purposes. (1) It can be
formally verified by the proof engine. (2) It provides enough information for
the human reader to convince him that the proof is correct.

\subsection{List Sorting}

In this chapter we develop a verified insertion sort algorithm for lists. For
the verification of the algorithm we use some functions and theorems of the
module \lstinline!list! of the base library. For completeness the used
functions and theorems are listed here.

\begin{lstlisting}
    -- from the module 'alba.base.list'
    G: ANY

    size (a:[G]): NATURAL
        -> inspect a
           case []  then 0
           case h^t then t.size.successor
           end

    (in) (x:G, a:[G]): BOOLEAN
            -- Is the element 'x' contained in the list 'a'?
        -> inspect a
           case []  then false
           case h^t then x=h or x in t
           end

    all_in (a:[G], p:G?): BOOLEAN
            -- Do all elements of the list 'a' satisfy the predicate 'p'?
        -> inspect a
           case []  then true
           case h^t then h in p and t.all_in(p)
           end

    all_in (a,b:[G]): BOOLEAN
            -- Are all elements of the list 'a' contained in the list 'b'?
        -> a.all_in(elements(b))


    same_elements (a,b:[G]): BOOLEAN
            -- Have the lists 'a' and 'b' the same elements
        -> a.all_in(b) and b.all_in(a)


    permutation (a,b:[G]): ghost BOOLEAN
        -> a.size = b.size and same_elements(a,b)

    all(a:[G], p,q:G?)
        ensure
            x in a ==> a.all_in(p) ==> x in p
            a.all_in(b) ==> b.all_in(p) ==> a.all_in(p)
            a.all_in(p) ==> p <= q ==> a.all_in(q)

            permutation(a,a)
            permutation(a,b) ==> permutation(b,a)
            permutation(a,b) ==> permutation(b,c) ==> permutation(a,c)
            permutation(x^y^a, y^x^a)
            permutation(a,b) ==> permutation(x^a,x^b)
        end
\end{lstlisting}

The sorting code we develop in this chapter need some modules of the base
library.

\begin{lstlisting}
    use
        alba.base.boolean_logic
        alba.base.predicate_logic
        alba.base.linear_order
        alba.base.list
    end
\end{lstlisting}

In an implementation file it is usually convenient to use the modules for
boolean logic and predicate logic because they provide us with many useful
laws of logic. We need a linear order because only list of elements which have
a linear order can be sorted. Furthermore we use the lists of the base library
because we want to sort lists.

Before trying to write a search function we need to define what it means for a
list to be sorted and the properties which sorted lists have. First we define
a function which tells whether an element is less than or equal all elements
in the list.



\begin{lstlisting}
    L: LINEAR_ORDER

    is_lower_bound (x:L, a:[L]): BOOLEAN
        -> a.all_in({y: x <= y})
\end{lstlisting}

This lower bound function has the following transitivity property:

\begin{lstlisting}
    all(x,y:L, a:[L])
            -- transitivity
        require
            x <= y
            y.is_lower_bound(a)
        proof
            {z: y <= z} <= {z: x <= z}
        ensure
            x.is_lower_bound(a)
        end
\end{lstlisting}

Furthermore we expect that a lower bound for a list is a lower bound for any
permutation of the list.

\begin{lstlisting}
    all(x:L, a,b:[L])
        require
            x.is_lower_bound(a); permutation(a,b)
        ensure
            x.is_lower_bound(b)
        end
\end{lstlisting}

Fortunately the proof engine accepts this assertion without any
intervention. It just expands the definitions of lower bounds and
permutations.



Now we have to define the notion of a sorted list. The empty list and the one
element list are always sorted. A list having more than one element is sorted
if the first two elements are sorted and the tail of the list is sorted.

\begin{lstlisting}
    is_sorted (l:[L]): BOOLEAN
        -> inspect l
           case []  then true   -- empty list
           case x^t then
               inspect t
               case []  then true  -- one element list
               case y^a then x <= y and t.is_sorted
               end
           end
\end{lstlisting}

\begin{quote}
  Note: Nested inspect expressions are needed because of a restriction in the
  version 0.2 of the compiler. In future versions a more readable equivalent
  expression can be used.
\begin{lstlisting}
    inspect l
    case []    then true
    case [_]   then true
    case x^y^t then x <= y and (y^t).is_sorted
    end  
\end{lstlisting}
\end{quote}

Now let us think a moment about properties which sorted lists should have.
\begin{itemize}
\item The tail of a sorted nonempty list should be sorted.
\item The head of a sorted list should be a lower bound for the tail of the list.
\item If a list is sorted then any lower bound of the list prepended should
  result in a sorted list as well.
\end{itemize}

These three properties can be proved by induction by just telling the proof
engine that we want a proof by induction.

\begin{lstlisting}
    all(x:L, a:[L])
        proof
            []  in {a: (x^a).is_sorted ==> a.is_sorted}
            a   in {a: (x^a).is_sorted ==> a.is_sorted}
        ensure
            (x^a).is_sorted ==> a.is_sorted
        end
\end{lstlisting}

\begin{lstlisting}
    all(x:L, a:[L])
        proof
            []  in {a: all(x) (x^a).is_sorted ==> x.is_lower_bound(a)}
            a   in {a: all(x) (x^a).is_sorted ==> x.is_lower_bound(a)}
        ensure
            (x^a).is_sorted ==> x.is_lower_bound(a)
        end
\end{lstlisting}

\begin{lstlisting}
    all(x:L, a:[L])
        require
            x.is_lower_bound(a)
            a.is_sorted
        proof
            []  in {a: x.is_lower_bound(a)
                       ==>  a.is_sorted
                       ==> (x^a).is_sorted}
            a   in {a: x.is_lower_bound(a)
                       ==>  a.is_sorted
                       ==> (x^a).is_sorted}
        ensure
            (x^a).is_sorted
        end
\end{lstlisting}

Note that in the second assertion the universal quantification over the
elements \lstinline!x! has been shifted into the predicate for the induction
proof. It is evident that the proof, if succeeds, implies the wanted
assertion. But this stronger predicate for the induction proof results in a
stronger induction hypothesis (because it is universally quantified over the
head element). With the stronger induction hypothesis the proof succeeds,
without it fails.

Now we have enough assertions to design a function which inserts an element
into a sorted list maintaining the list sorted. Inserting into an empty list
is trivial since the one element list is always sorted.

Look at the case that we want to insert an element \lstinline!x! into an
already sorted list \lstinline!y^a!. There are two cases: \lstinline!x <= y!
and \lstinline!not (x <= y)!. In the first case the new element is a lower
bound of the list and can therefore be prepended without destroying the
sorting. In the second case we know that \lstinline!y! is a lower bound of any
permutation of \lstinline!x^a!. I.e. the list with the head element
\lstinline!y! put in front the \lstinline!x! inserted ordered into
\lstinline!a! is sorted as well.

\begin{lstlisting}
    into (x:L, l:[L]): [L]
        -> inspect l
           case []  then [x]
           case y^a then
               if x <= y then x^y^a else y ^ x.into(a) end
           end
\end{lstlisting}

We claim that the function \lstinline!into! returns a list which is a
permutation of \lstinline!x^a! and sorted. Before trying to prove these facts
by induction let us look at the different cases separately.

The insertion of an element into the empty list maintains the permutation
property.

\begin{lstlisting}
    all(x:L)
        proof
            x.into([]) = [x]
        ensure
            permutation ([x], x.into([]))
        end
\end{lstlisting}

The induction step requires to distinguish two cases because the function
\lstinline!into! contains an if expression for insertion into a nonempty
list. We prove the permutation property separately for the two cases.

\begin{lstlisting}
    all(x,y:L, a:[L])
        require
            permutation(x^a, x.into(a))
            x <= y
        proof
             x.into(y^a) = x^y^a
        ensure
            permutation(x^y^a, x.into(y^a))
        end
\end{lstlisting}

\begin{lstlisting}
    all(x,y:L, a:[L])
        require
            permutation(x^a, x.into(a))
            not (x <= y)
        proof
            permutation(x^y^a, y^x^a)        -- module list
            permutation(y^x^a, y^x.into(a))  -- ind hypo/list
            proof
                x.into(y^a) = y^x.into(a)
                y^x.into(a) in {l: permutation(l,x.into(y^a))}
            ensure
                permutation(y^x.into(a), x.into(y^a))
            end
        ensure
            permutation(x^y^a, x.into(y^a))
        end
\end{lstlisting}

Having these two lemmas the proof by induction of the permutation property is
easy.

\begin{lstlisting}
    all(x:L, a:[L])
        proof
            [] in {a: permutation (x^a, x.into(a))}

            all(y:L, a:[L])
                require
                    permutation(x^a, x.into(a))
                proof
                    x <= y or not (x <= y)

                    x <= y       ==> permutation(x^y^a, x.into(y^a))
                    not (x <= y) ==> permutation(x^y^a, x.into(y^a))
                ensure
                    permutation(x^y^a, x.into(y^a))
                end

            a in {a: permutation (x^a, x.into(a))}
        ensure
            permutation (x^a, x.into(a))
        end
\end{lstlisting}

In order to prove the sortedness of the resulting list we have to make the
same case split in the induction step.

\begin{lstlisting}
    all(x:L, a:[L])
        proof
            []  in {a: a.is_sorted ==> x.into(a).is_sorted}

            all(x,y:L, a:[L])
                require
                    a.is_sorted ==> x.into(a).is_sorted
                    (y^a).is_sorted
                proof
                    x <= y or not (x <= y)

                    require x <= y
                    ensure  x.into(y^a).is_sorted end

                    require not (x <= y)
                    proof   y.is_lower_bound(x^a)
                            permutation(x^a, x.into(a))
                            (y^x.into(a)).is_sorted
                    ensure  x.into(y^a).is_sorted end                
                ensure
                    x.into(y^a).is_sorted
                end

            a in {a: a.is_sorted ==> x.into(a).is_sorted}
        ensure
            a.is_sorted ==> x.into(a).is_sorted
        end
\end{lstlisting}

The insertion of one element into a sorted list has been the hard part. In
order to sort the list completely we just have to step recursively through the
elements and insert one by one into an initially empty list.

\begin{lstlisting}
    sorted (a:[L]): [L]
        -> inspect a
           case []  then [] 
           case h^t then h.into(t.sorted)
           end
\end{lstlisting}

The proofs of the permutation property and the sortedness is just an
application of the standard template for doing induction proofs with some help
at the induction step.

\begin{lstlisting}
    all(a:[L])
        proof
            [] in {a: permutation(a, a.sorted)}
            all(x:L, a:[L])
                require
                    permutation(a, a.sorted)
                proof
                    permutation(x^a, x^a.sorted)
                    permutation(x^a.sorted, x.into(a.sorted))
                    proof  x.into(a.sorted) = (x^a).sorted
                    ensure permutation(x.into(a.sorted),
                                       (x^a).sorted) end
                ensure
                    permutation(x^a, (x^a).sorted)
                end
            a in {a: permutation(a, a.sorted)}
        ensure
            permutation(a, a.sorted)
        end
\end{lstlisting}

\begin{lstlisting}
    all(a:[L])
        proof
            [] in {a: a.sorted.is_sorted}

            all(x:L,a:[L])
                require
                    a.sorted.is_sorted
                proof
                    x.into(a.sorted).is_sorted
                ensure
                    (x^a).sorted.is_sorted
                end

            a in {a: a.sorted.is_sorted}
        ensure
            a.sorted.is_sorted
        end
\end{lstlisting}


%%% Local Variables: 
%%% mode: latex
%%% case-fold-search: nil
%%% TeX-master: "albatross"
%%% End: 
